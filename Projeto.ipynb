{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heffx/CNN/blob/master/Projeto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eyzYCyRsH8-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xcQbTMMpIj74",
        "colab_type": "code",
        "outputId": "202adacc-ae65-4037-8705-58c59ad6bdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Conferindo se o CUDA esta disponivel\n",
        "\n",
        "verificaGPU = torch.cuda.is_available()\n",
        "\n",
        "if not verificaGPU:\n",
        "  print('CUDA INDISPONIVEL, TREINANDO COM CPU')\n",
        "else:\n",
        "  print('CUDA DISPONIVEL, TREINANDO COM GPU')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA DISPONIVEL, TREINANDO COM GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mTFSdb4gRK33",
        "colab_type": "code",
        "outputId": "bb8ce0c1-0b6d-4845-88fa-e29a2ab43bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4yFeiycn3-SW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fazendo download e descompactando o dataset\n",
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "!rm -r flower_data || true\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMiRF1Q9Ff6V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import json\n",
        "import copy\n",
        "import os\n",
        "import flower_data\n",
        "from torchvision import datasets\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, models, transforms\n",
        "import glob\n",
        "import numpy as np\n",
        "from skimage import data, io, filters\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNhMUsEXUQY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Carregando, Normalizando e Criando vetor de Imagens"
      ]
    },
    {
      "metadata": {
        "id": "f9eRXgPli5Qf",
        "colab_type": "code",
        "outputId": "ec4e784c-7edc-4f1e-c403-d010a2163e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "#Carregando treino com data loader\n",
        "imagenet_train = torchvision.datasets.ImageFolder('flower_data/train/')\n",
        "\n",
        "imagenet_valid = torchvision.datasets.ImageFolder('flower_data/valid/')\n",
        "                                                 \n",
        "                                                 \n",
        "print(imagenet_train)\n",
        "print(imagenet_valid)\n",
        "data_loader_train = torch.utils.data.DataLoader(imagenet_train,\n",
        "                                          batch_size=10,\n",
        "                                          shuffle=True)\n",
        "\n",
        "data_loader_valid = torch.utils.data.DataLoader(imagenet_valid,\n",
        "                                          batch_size=10,\n",
        "                                          shuffle=True)\n",
        "\n",
        "print(data_loader_train)\n",
        "print(data_loader_valid)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 6552\n",
            "    Root Location: flower_data/train/\n",
            "    Transforms (if any): None\n",
            "    Target Transforms (if any): None\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 818\n",
            "    Root Location: flower_data/valid/\n",
            "    Transforms (if any): None\n",
            "    Target Transforms (if any): None\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7fd1fcc26128>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7fd1c349add8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ORyh1oX9goG0",
        "colab_type": "code",
        "outputId": "44cf99ca-e9a0-4b64-906c-4d5f044cf6df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(data_transforms)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': Compose(\n",
            "    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "), 'valid': Compose(\n",
            "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xFIDfbRXu3gO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_images(path):\n",
        "  classes = glob.glob(path + '*')\n",
        "  im_files = []\n",
        "  size_classes = []\n",
        "  for i in classes:\n",
        "    # Agrupa as imagens por classe\n",
        "    name_images_per_class = glob.glob(i+ '/*')\n",
        "    im_files = im_files+name_images_per_class\n",
        "    # Agrupa a quantidade de cada classe no vetor size_class\n",
        "    size_classes.append(len(name_images_per_class))\n",
        "  labels = np.zeros((len(im_files), len(classes)))\n",
        "  ant = 0\n",
        "  \n",
        "  for id_i, i in enumerate(size_classes):\n",
        "    labels[ant:ant+i, id_i] = 1\n",
        "    ant = i\n",
        "  collection = io.imread_collection(im_files)\n",
        "  data = []\n",
        "  \n",
        "  for id_i, i in enumerate(collection):\n",
        "    data.append(i)\n",
        "  return np.asarray(data) , np.asarray(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RQjT-K27NLyF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load Train\n",
        "\n",
        "path = 'flower_data/valid/'\n",
        "data = []\n",
        "labels = []\n",
        "data, labels = read_images(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HFw24yhb_c6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bf1f1c20-a799-4a27-ccb7-7f5094838f4a"
      },
      "cell_type": "code",
      "source": [
        "print(type(data))\n",
        "print(data.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(818,)\n",
            "(818, 102)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BnHNh4iNAq1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plotando uma das imagens\n",
        "#plt.imshow(data[0].numpy().squeeze(), cmap = 'Greys_r')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}