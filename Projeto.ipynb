{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heffx/CNN/blob/master/Projeto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eyzYCyRsH8-h",
        "colab_type": "code",
        "outputId": "06c1b76a-5f15-4b47-984c-b981cc688eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "#Importando o Pytorch\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m  HTTP error 403 while getting http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\u001b[0m\n",
            "\u001b[31m  Could not install requirement torch==0.4.1 from http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl because of error 403 Client Error: Forbidden for url: http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\u001b[0m\n",
            "\u001b[31mCould not install requirement torch==0.4.1 from http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl because of HTTP error 403 Client Error: Forbidden for url: http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl for URL http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xcQbTMMpIj74",
        "colab_type": "code",
        "outputId": "610169e1-cae7-48cb-c1db-18d72b99e581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Conferindo se o CUDA esta disponivel\n",
        "\n",
        "verificaGPU = torch.cuda.is_available()\n",
        "\n",
        "if not verificaGPU:\n",
        "  print('CUDA INDISPONIVEL, TREINANDO COM CPU')\n",
        "else:\n",
        "  print('CUDA DISPONIVEL, TREINANDO COM GPU')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA DISPONIVEL, TREINANDO COM GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mTFSdb4gRK33",
        "colab_type": "code",
        "outputId": "c59d104d-9656-4f84-c371-f158a811c14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Instalando o Torch Vision\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxFpAD8xTusN",
        "colab_type": "code",
        "outputId": "53810b30-7233-42a0-b28f-9b0bff898e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# Instalando Pillow\n",
        "!pip install Pillow==4.1.1\n",
        "\n",
        "!pip install image"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow==4.1.1 in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.1.1) (0.46)\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.1.1)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.5)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4yFeiycn3-SW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fazendo download e descompactando o dataset\n",
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "!rm -r flower_data || true\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMiRF1Q9Ff6V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Todos os imports necessários'\n",
        "import time\n",
        "import json\n",
        "import copy\n",
        "import flower_data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import os\n",
        "from skimage import data, io, filters\n",
        "from scipy.optimize import minimize\n",
        "import cv2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qNt-6tDkYx4X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definindo variavel global para treinamento com CUDA\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNhMUsEXUQY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Carregando, Normalizando e Criando vetor de Imagens"
      ]
    },
    {
      "metadata": {
        "id": "ORyh1oX9goG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Aumento e normalização de dados para treinamento\n",
        "# Apenas normalização para validação\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        # Redimensiona a imagem em (224,224)\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        # Inverte horizontalmente a imagem\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        # Transforma em matriz de dados unicos\n",
        "        transforms.ToTensor(),\n",
        "        # Normaliza as imagens atraves de desvio padrão(Valores retirados de outro trabalho) \n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        \n",
        "        # Redimensiona a imagem em (224,224)\n",
        "        #transforms.RandomResizedCrop(224),\n",
        "        # Transformação da imagem para tamanho de entrada\n",
        "         transforms.Resize(256),\n",
        "        # Recorta a imagem no centro\n",
        "         transforms.CenterCrop(224),\n",
        "        # Transforma em matriz de dados unicos\n",
        "        transforms.ToTensor(),\n",
        "        # Normaliza as imagens atraves de desvio padrão(Valores retirados de outro trabalho) \n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "# print(data_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6yE5HHrKXfTT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Definindo nome dos diretorios de forma global para todo o código\n",
        "train_dir = 'flower_data/train/'\n",
        "valid_dir = 'flower_data/valid/'\n",
        "dirs = {'train': train_dir, \n",
        "        'valid': valid_dir, \n",
        "       }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yg_i22ryV5AT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Carregando as pastas do dataset\n",
        "image_datasets = {x: datasets.ImageFolder(dirs[x],\n",
        "                                          transform = data_transforms[x])\n",
        "                  for x in ['train', 'valid']}\n",
        "\n",
        "# Carregando imagens do dataset de treino e validação em  lotes\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
        "                                              batch_size=32, shuffle=True) \n",
        "               for x in ['train', 'valid']}\n",
        "\n",
        "# Carregando tamanho do dataset de treino e validação\n",
        "dataset_sizes = {x: len(image_datasets[x]) \n",
        "                              for x in ['train', 'valid']}\n",
        "\n",
        "# Carregando as classes do dataset de treino\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pp2d2zMBZBGO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(dataset_sizes)\n",
        "# print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kkYTDVkDZP-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Carregando arquivo Json\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQu7vOXfZGDI",
        "colab_type": "code",
        "outputId": "ac68e4e7-2fc0-4959-8b9a-3c1216ed39cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Atribuindo o nome das classes com o arquivo Json\n",
        "images, labels = next(iter(dataloaders['train']))\n",
        "images.size()\n",
        "images, labels = next(iter(dataloaders['train']))\n",
        "rand_idx = np.random.randint(len(images))\n",
        "# print(rand_idx)\n",
        "print(\"label: {}, class: {}, name: {}\".format(labels[rand_idx].item(),\n",
        "                                               class_names[labels[rand_idx].item()],\n",
        "                                               cat_to_name[class_names[labels[rand_idx].item()]]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: 90, class: 89, name: watercress\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9KKCZznmYyVg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Função de treino da rede"
      ]
    },
    {
      "metadata": {
        "id": "hLzay5BoZxJr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, criteria, optimizer, scheduler,    \n",
        "                                      num_epochs=25, device='cuda'):\n",
        "    \n",
        "    # Variável que calcula tempo gasto pelo modelo\n",
        "    since = time.time()\n",
        "    \n",
        "    # Recebe os melhores parametros do modelo a cada iteração\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    # Variável que calcula melhor acurácia\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    # FOR que roda todas as iterações\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Época {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Cada época tem uma fase de treinamento e validação\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Definir modelo para o modo de treinamento\n",
        "            else:\n",
        "                model.eval()   # Definir modelo para avaliar o modo\n",
        "            \n",
        "            # Várivel que recebe os erros da rede\n",
        "            running_loss = 0.0\n",
        "            # Várivel que recebe os acertos da rede\n",
        "            running_corrects = 0.0\n",
        "\n",
        "            # Carregando os bancos de dados.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "             \n",
        "\n",
        "                # Zerando os gradientes dos parâmetros\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                # Set histórico somente no treinamento\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward + optimize somente na fase de treinamento\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        \n",
        "                # Estátisticas\n",
        "                # A cada erro da rede o valor e armazenado na váriavel running_loss\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "             \n",
        "                # A cada acerto da rede o valor e armazenado na váriavel running_corrects\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # Cálculo do valor de erros a cada iteração de epóca\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            # Cálculo do valor da acurácia a cada iteração de epóca\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            # Printa na tela o valor de erros e da acuracia no treino e na validação\n",
        "            print('{} Loss: {:.4f} Acurácia: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # Armazena dados da rede na fase de validação\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                # Armazena a época que que a rede teve melhor valor de acurácia \n",
        "                best_acc = epoch_acc\n",
        "                # Armazena os parametros para próxima iteração da rede\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "    \n",
        "    # Variavel que recebe o valor total do tempo gasto pelo modelo\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Treino completo em {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    # Printa na tela o maior de valor acurácia\n",
        "    print('Melhor Acurácia: {:4f}'.format(best_acc))\n",
        "\n",
        "    # Carrega os parametros da rede\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    # Retorna o modelo\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6VqOZrTfrBQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pré-treino VGG 19"
      ]
    },
    {
      "metadata": {
        "id": "MMs_QtMaY0_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Carregando em model a rede VGG19\n",
        "model = models.vgg19(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yaE5zsTwuctm",
        "colab_type": "code",
        "outputId": "a000d324-620d-4014-c807-cda192cd97e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "cell_type": "code",
      "source": [
        "# Verificando se o modelo foi carregado corretamente\n",
        "model"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace)\n",
              "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace)\n",
              "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace)\n",
              "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): ReLU(inplace)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): ReLU(inplace)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): ReLU(inplace)\n",
              "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (33): ReLU(inplace)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): ReLU(inplace)\n",
              "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace)\n",
              "    (2): Dropout(p=0.5)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace)\n",
              "    (5): Dropout(p=0.5)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "UXHrmOP7ujLE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Definindo a arquitetura da rede\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(25088,4096)\n",
        "    self.fc2 = nn.Linear(4096,102)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    # Verifica se o tensor está \"flattened (achatado)\"\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.log_softmax(self.fc2(x),dim=1)\n",
        "    \n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZEwR5kcxCQXr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = Classifier()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4QCVrPUFHoH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if verificaGPU:\n",
        "    model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mEFtihyXGGo8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Criteria NLLLoss which is recommended with Softmax final layer\n",
        "criterion = nn.NLLLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optim = torch.optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "# Decay LR by a factor of 0.1 every 4 epochs\n",
        "sched = lr_scheduler.StepLR(optim, step_size=4, gamma=0.1)\n",
        "# Number of epochs\n",
        "eps=30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajBxkhg9fyqo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Treinando a rede com o modelo VGG"
      ]
    },
    {
      "metadata": {
        "id": "dK_QACUYZ3Li",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_ft = train_model(model, criterion, optim, sched, eps, 'cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tTum9yLf_4S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Salvando modelo"
      ]
    },
    {
      "metadata": {
        "id": "w6IV24WsCSgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Salvando Modelo\n",
        "model.class_to_idx = image_datasets['train'].class_to_idx\n",
        "model.cpu()\n",
        "torch.save({'arch': 'vgg19',\n",
        "            'state_dict': model.state_dict(), \n",
        "            'class_to_idx': model.class_to_idx}, \n",
        "            'VGG19.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fC3bNHozgCXq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pré-treino AlexNet"
      ]
    },
    {
      "metadata": {
        "id": "oMBvTEI-zdTL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_alex = models.alexnet(pretrained=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKgGJgbdG8Mg",
        "colab_type": "code",
        "outputId": "2b8a8efc-a987-4487-f23c-f3fe57482127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model_alex.classifier[1].in_features"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_hiLM7eEMTtB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h5Sh_gkPEtkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#if verificaGPU:\n",
        "#    model_alex.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZQQQ8DFLC34",
        "colab_type": "code",
        "outputId": "fb75b27c-1ac8-4311-c021-3a8207134e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "model_alex.to(device)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace)\n",
              "    (3): Dropout(p=0.5)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "zZrbf5y-QduL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optim_alex = torch.optim.SGD(params = model_alex.parameters(), lr=0.09)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ft_bu3VcDaWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion_alex = nn.PoissonNLLLoss()\n",
        "\n",
        "sched_alex = lr_scheduler.StepLR(optim_alex, step_size=2, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iLwagVMpgKPQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Treinando a rede com o modelo AlexNet"
      ]
    },
    {
      "metadata": {
        "id": "ta1B4h3G0dY8",
        "colab_type": "code",
        "outputId": "80a7b5ed-6a62-4e29-cd25-80482921127c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_alex, criterion_alex, optim_alex, sched_alex, 10, 'cuda')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Época 0/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0053\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 1/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 2/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 3/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 4/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 5/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 6/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 7/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 8/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 9/9\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Treino completo em 19m 26s\n",
            "Melhor Acurácia: 0.009780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DYbD7iD0SliE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4148
        },
        "outputId": "fbdc17ae-eaa2-4cee-be45-6938e4039745"
      },
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_alex, criterion_alex, optim_alex, sched_alex, 100, 'cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Época 0/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 1/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 2/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 3/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 4/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 5/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 6/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 7/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 8/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 9/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 10/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 11/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 12/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 13/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 14/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 15/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 16/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 17/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 18/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 19/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 20/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 21/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 22/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 23/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 24/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 25/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 26/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 27/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 28/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 29/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 30/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 31/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 32/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 33/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 34/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 35/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 36/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 37/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 38/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 39/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 40/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 41/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 42/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 43/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 44/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 45/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 46/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 47/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n",
            "valid Loss: nan Acurácia: 0.0098\n",
            "\n",
            "Época 48/99\n",
            "----------\n",
            "train Loss: nan Acurácia: 0.0041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "diVRGfRmgaII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Salvando Modelo"
      ]
    },
    {
      "metadata": {
        "id": "fjTZXYGp0hTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Salvando Modelo\n",
        "#torch.save(model_alex.state_dict(), './alexnet.pth')\n",
        "\n",
        "model.class_to_idx = image_datasets['train'].class_to_idx\n",
        "model.cpu()\n",
        "torch.save({'arch': 'AlexNet',\n",
        "            'state_dict': model.state_dict(), \n",
        "            'class_to_idx': model.class_to_idx}, \n",
        "            'AlexNet.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEsB3KLqghKd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predição "
      ]
    },
    {
      "metadata": {
        "id": "ix-IdWLmmc6H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Processa a imagem como no modelo\n",
        "def process_image(image_path):\n",
        "    \n",
        "    # Abrindo a imagem\n",
        "    img = Image.open(image_path)\n",
        "    \n",
        "    # Resize\n",
        "    if img.size[0] > img.size[1]:\n",
        "        img.thumbnail((10000, 256))\n",
        "    else:\n",
        "        img.thumbnail((256, 10000))\n",
        "    # Crop \n",
        "    left_margin = (img.width-224)/2\n",
        "    bottom_margin = (img.height-224)/2\n",
        "    right_margin = left_margin + 224\n",
        "    top_margin = bottom_margin + 224\n",
        "    img = img.crop((left_margin, bottom_margin, right_margin,   \n",
        "                      top_margin))\n",
        "    # Normalize\n",
        "    img = np.array(img)/255\n",
        "    mean = np.array([0.485, 0.456, 0.406]) #provided mean\n",
        "    std = np.array([0.229, 0.224, 0.225]) #provided std\n",
        "    img = (img - mean)/std\n",
        "    \n",
        "    # Move os canais de cor para a primeira dimensão conforme esperado pelo PyTorch\n",
        "    img = img.transpose((2, 0, 1))\n",
        "    \n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jvrtBoOlp81b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Função que recebe a imagem, o modelo, e o numero de classes vc quer que ele apresente.\n",
        "def predict(image_path, model, top_num=5):\n",
        "   \n",
        "    # Processa a imagem com a função acima\n",
        "    img = process_image(image_path)\n",
        "    \n",
        "    # Numpy -> Tensor\n",
        "    image_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n",
        "    # Muda o lote para tamanho 1\n",
        "    model_input = image_tensor.unsqueeze(0)\n",
        "    # Testa a probabilidade com o modelo\n",
        "    probs = torch.exp(model.forward(model_input))\n",
        "    # Recebe os principais modelos retornados pela rede\n",
        "    top_probs, top_labs = probs.topk(top_num)\n",
        "    top_probs = top_probs.detach().numpy().tolist()[0] \n",
        "    top_labs = top_labs.detach().numpy().tolist()[0]\n",
        "    # converte os indices recebidos no nome das classes\n",
        "    idx_to_class = {val: key for key, val in    \n",
        "                                      model.class_to_idx.items()}\n",
        "    top_labels = [idx_to_class[lab] for lab in top_labs]\n",
        "    top_flowers = [cat_to_name[idx_to_class[lab]] for lab in top_labs]\n",
        "    \n",
        "    # Retorno para a função de plot\n",
        "    return top_probs, top_labels, top_flowers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dL13K_iop-xk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Função de plotar resultado da predição\n",
        "def plot_solution(image_path, model):\n",
        "    # Set plot\n",
        "    plt.figure(figsize = (6,10))\n",
        "    ax = plt.subplot(2,1,1)\n",
        "    # Set titulo\n",
        "    #Carrega o numero da classe da flor\n",
        "    flower_num = image_path.split('/')[2]\n",
        "    # Carrega o nome da classe de acordo com o numero obtido acima\n",
        "    title_ = cat_to_name[flower_num]\n",
        "    # Plot flor\n",
        "    img = process_image(image_path)\n",
        "    imshow(img, ax, title = title_);\n",
        "    # Recendo previsão da função acima\n",
        "    probs, labs, flowers = predict(image_path, model) \n",
        "    # Plot gráfico de barras\n",
        "    plt.subplot(2,1,2)\n",
        "    sns.barplot(x=probs, y=flowers, color=sns.color_palette()[0]);\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eukDBTCcx7mC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_path = 'flower_data/valid/29/image_04143.jpg'\n",
        "plot_solution(image_path, model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}